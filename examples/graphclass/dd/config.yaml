# DD Graph Classification configuration

data:
  name: DD
  root: ${oc.env:HOME}/.cache/energy-transformer/data
  # DD specific settings
  max_num_nodes: 300  # Reduced significantly to save memory
  batch_size: 2   # Minimal batch size for very large graphs
  use_node_attr: false  # DD has node labels only
  cleaned: false
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  pos_encoding_method: eigen
  num_workers: 0

model:
  input_dim: 89   # DD has 89D one-hot node labels
  out_dim: 2      # Binary classification
  embed_dim: 32   # Minimal embedding size
  num_heads: 2    # Minimal heads
  qk_dim: 8       # Minimal qk dimension
  pos_encoding_dim: 4  # Minimal positional encoding
  num_layers: 1
  mlp_ratio: 1.0  # Minimal MLP
  num_time_steps: 2  # Fewer time steps
  step_size: 1.0
  norm_eps: 1e-6
  attn_bias: false
  mlp_bias: false
  hopfield_activation_type: gelu  # Use GELU activation

train:
  epochs: 200
  optimizer:
    lr: 3e-4
    weight_decay: 0.0001
  gradient_clip: 1.0
  gradient_accumulation_steps: 8  # High gradient accumulation
  scheduler:
    enabled: false

# Misc
seed: 3407
save_interval: 10
checkpoint_dir: checkpoints/${data.name}
result_dir: results/${data.name}
visualization_dir: visualizations/${data.name}

# Hydra configuration
hydra:
  run:
    dir: outputs/${data.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${data.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job:
    chdir: true